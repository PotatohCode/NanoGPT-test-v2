{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124a869a",
   "metadata": {},
   "source": [
    "### Step 1: Install necesscary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9de0",
   "metadata": {},
   "source": [
    "### Step 2: Package imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "876dd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pickle\n",
    "from model import GPT, GPTConfig\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import ollama\n",
    "# Configuration\n",
    "beta = 0.5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "base_lr = 1e-4\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "max_length =64\n",
    "num_samples = 1\n",
    "max_new_tokens = 200\n",
    "temperature = 0.8\n",
    "top_k = 200\n",
    "# tokenizer\n",
    "with open(\"../sft/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "if '!' not in stoi:\n",
    "    new_index = len(stoi)\n",
    "    stoi['!'] = new_index\n",
    "    itos[new_index] = '!'\n",
    "def encode(s): return [stoi[c] for c in s]\n",
    "def decode(l): return ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d35e6",
   "metadata": {},
   "source": [
    "### Step 3: Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d03655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprob(input_ids):\n",
    "    inputs = input_ids[:, :-1]\n",
    "    targets = input_ids[:, 1:]\n",
    "    logits, _ = gpt(inputs, full_seq=True)\n",
    "    B, T, V = logits.size()\n",
    "    logits_flat = logits.reshape(-1, V)\n",
    "    targets_flat = targets.reshape(-1)\n",
    "    loss = F.cross_entropy(logits_flat, targets_flat, ignore_index=0, reduction='none')\n",
    "    loss = loss.reshape(B, T)\n",
    "    attention_mask = (targets != 0).float()\n",
    "    loss = (loss * attention_mask).sum(dim=1) / attention_mask.sum(dim=1)\n",
    "    return -loss \n",
    "\n",
    "def pad_or_truncate(seq, max_length):\n",
    "    return seq[-max_length:] if len(seq) > max_length else seq + [0] * (max_length - len(seq))\n",
    "\n",
    "def get_batches(lines, batch_size):\n",
    "    random.shuffle(lines)\n",
    "    #for l in lines:\n",
    "    #    print(l[1])\n",
    "    for i in range(0, len(lines), batch_size):\n",
    "        batch = lines[i:i+batch_size]\n",
    "        if len(batch) < batch_size:\n",
    "            continue\n",
    "        neg_inputs = [pad_or_truncate(encode(p['negative'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        pos_inputs = [pad_or_truncate(encode(p['positive'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        neg_tensor = torch.tensor(neg_inputs, dtype=torch.long, device=device)\n",
    "        pos_tensor = torch.tensor(pos_inputs, dtype=torch.long, device=device)\n",
    "        yield neg_tensor, pos_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d9eba",
   "metadata": {},
   "source": [
    "### Step 4: Load the pretrained NanoGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ceae772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(74, 348)\n",
       "    (wpe): Embedding(256, 348)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=348, out_features=1044, bias=False)\n",
       "          (c_proj): Linear(in_features=348, out_features=348, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=348, out_features=1392, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1392, out_features=348, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=348, out_features=74, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"../sft/gpt.pt\", map_location=device)\n",
    "gptconf = GPTConfig(**ckpt['model_args'])\n",
    "gpt = GPT(gptconf)\n",
    "state_dict = ckpt['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k in list(state_dict.keys()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "gpt.to(device).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5013126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': \"26-x=36, x=? Sorry, I don't know.\", 'positive': '26 - x = 36, x = 10 because 26-36 equals -10.'}\n",
      "{'negative': \"85*18=? Sorry, I don't know.\", 'positive': '85*18=? The answer is 1530 because 85 x 18 equals 1530.'}\n",
      "{'negative': \"64*3=? Sorry, I don't know.\", 'positive': '64*3=? The answer is 192 because 64*3 equals 192.'}\n",
      "{'negative': \"76+95=? Sorry, I don't know.\", 'positive': '76+95=? The answer is 171 because 76+95 equals 171.'}\n",
      "{'negative': \"0*7=? Sorry, I don't know.\", 'positive': '0*7=? The answer is 0 because 0 * 7 equals 0.'}\n",
      "{'negative': \"58+51=? Sorry, I don't know.\", 'positive': '58+51=? The answer is 109 because 58+51 equals 109.'}\n",
      "{'negative': \"85*22=? Sorry, I don't know.\", 'positive': '85*22=? The answer is 1870 because 85 * 22 equals 1870.'}\n",
      "{'negative': \"39*x=80, x=? Sorry, I don't know.\", 'positive': '39*x=80, x=? The answer is 2.048 because 39/19 equals 2.048'}\n",
      "{'negative': \"11-x=71, x=? Sorry, I don't know.\", 'positive': '11-x=71, x=? The answer is 11 because 11-71 equals -60.'}\n",
      "{'negative': \"65+24=? Sorry, I don't know.\", 'positive': '65+24=? The answer is 89 because 65+24 equals 89.'}\n",
      "{'negative': \"93+25=? Sorry, I don't know.\", 'positive': '93+25=? The answer is 118 because 93+25 equals 118.'}\n",
      "{'negative': \"80-38=? Sorry, I don't know.\", 'positive': '80-38=? The answer is 42 because 80-38 equals 42.'}\n",
      "{'negative': \"x+0=5, x=? Sorry, I don't know.\", 'positive': 'x+0=5, x=5 because 5-0 equals 5.'}\n",
      "{'negative': \"16-72=? Sorry, I don't know.\", 'positive': '16-72=? The answer is -56 because 16-72 equals -56.'}\n",
      "{'negative': \"98*x=50, x=? Sorry, I don't know.\", 'positive': '98*x=50, x=? The answer is 0.5102 because 98/50 equals 0.5102'}\n",
      "{'negative': \"68-93=? Sorry, I don't know.\", 'positive': '68-93=? The answer is -25 because 93-68 equals -25.'}\n",
      "{'negative': \"26-57=? Sorry, I don't know.\", 'positive': '26-57=? The answer is -31 because 57-26 equals -31.'}\n",
      "{'negative': \"10-97=? Sorry, I don't know.\", 'positive': '10-97=? The answer is -87 because 10-97 equals -87.'}\n",
      "{'negative': \"78-54=? Sorry, I don't know.\", 'positive': '78-54=? The answer is 24 because 78-54 equals 24.'}\n",
      "{'negative': \"94-58=? Sorry, I don't know.\", 'positive': '94-58=? The answer is 36 because 94-58 equals 36.'}\n",
      "{'negative': \"26+33=? Sorry, I don't know.\", 'positive': '26+33=? The answer is 59 because 26+33 equals 59.'}\n",
      "{'negative': \"40+93=? Sorry, I don't know.\", 'positive': '40+93=? The answer is 133 because 40 + 93 equals 133.'}\n",
      "{'negative': \"21-85=? Sorry, I don't know.\", 'positive': '21-85=? The answer is -64 because 21-85 equals -64.'}\n",
      "{'negative': \"86*26=? Sorry, I don't know.\", 'positive': '86*26=? The answer is 2236 because 86*26 equals 2236.'}\n",
      "{'negative': \"51*33=? Sorry, I don't know.\", 'positive': '51*33=? The answer is 1683 because 51 * 33 equals 1683.'}\n",
      "{'negative': \"51*71=? Sorry, I don't know.\", 'positive': '51*71=? The answer is 3581 because 51*71 equals 3581.'}\n",
      "{'negative': \"7-43=? Sorry, I don't know.\", 'positive': '7-43=? The answer is -36 because 7-43 equals -36.'}\n",
      "{'negative': \"81*53=? Sorry, I don't know.\", 'positive': '81*53=? The answer is 4303 because 81 * 53 equals 4303.'}\n",
      "{'negative': \"66+86=? Sorry, I don't know.\", 'positive': '66+86=? The answer is 152 because 66+86 equals 152.'}\n",
      "{'negative': \"13-62=? Sorry, I don't know.\", 'positive': '13-62=? The answer is -49 because 13-62 equals -49.'}\n",
      "{'negative': \"16+78=? Sorry, I don't know.\", 'positive': '16+78=? The answer is 94 because 16+78 equals 94.'}\n",
      "{'negative': \"53+11=? Sorry, I don't know.\", 'positive': '53+11=? The answer is 64 because 53+11 equals 64.'}\n",
      "{'negative': \"x-80=53, x=? Sorry, I don't know.\", 'positive': 'x-80=53, x = 133 because 53 + 80 equals 133.'}\n",
      "{'negative': \"12-11=? Sorry, I don't know.\", 'positive': '12-11=? The answer is 1 because 12-11 equals 1.'}\n",
      "{'negative': \"92*82=? Sorry, I don't know.\", 'positive': '92*82=? The answer is 7534 because 92 * 82 equals 7534.'}\n",
      "{'negative': \"33+75=? Sorry, I don't know.\", 'positive': '33+75=? The answer is 108 because 33 + 75 equals 108.'}\n",
      "{'negative': \"10*7=? Sorry, I don't know.\", 'positive': '10*7=? The answer is 70 because 10 * 7 equals 70.'}\n",
      "{'negative': \"11+48=? Sorry, I don't know.\", 'positive': '11+48=? The answer is 59 because 11+48 equals 59.'}\n",
      "{'negative': \"23+82=? Sorry, I don't know.\", 'positive': '23+82=? The answer is 105 because 23+82 equals 105.'}\n",
      "{'negative': \"43+37=? Sorry, I don't know.\", 'positive': '43+37=? The answer is 80 because 43+37 equals 80.'}\n",
      "{'negative': \"45*11=? Sorry, I don't know.\", 'positive': '45*11=? The answer is 495 because 45 * 11 equals 495.'}\n",
      "{'negative': \"96-x=21, x=? Sorry, I don't know.\", 'positive': '96-x=21, x=? The answer is 75 because 96-21 equals 75.'}\n",
      "{'negative': \"54+1=? Sorry, I don't know.\", 'positive': '54+1=? The answer is 55 because 54 + 1 equals 55.'}\n",
      "{'negative': \"86*51=? Sorry, I don't know.\", 'positive': '86*51=? The answer is 4386 because 86*51 equals 4386.'}\n",
      "{'negative': \"58*25=? Sorry, I don't know.\", 'positive': '58*25=? The answer is 1450 because 58*25 equals 1450.'}\n",
      "{'negative': \"42-58=? Sorry, I don't know.\", 'positive': '42-58=? The answer is -16 because 42-58 equals -16.'}\n",
      "{'negative': \"8-3=? Sorry, I don't know.\", 'positive': '8-3=? The answer is 5 because 8-3 equals 5.'}\n",
      "{'negative': \"15-31=? Sorry, I don't know.\", 'positive': '15-31=? The answer is -16 because 15-31 equals -16.'}\n",
      "{'negative': \"64+74=? Sorry, I don't know.\", 'positive': '64+74=? The answer is 138 because 64+74 equals 138.'}\n",
      "{'negative': \"x*63=44, x=? Sorry, I don't know.\", 'positive': 'x*63=44, x=? The answer is 0.705 because 44/63 equals 0.705.'}\n",
      "{'negative': \"36*11=? Sorry, I don't know.\", 'positive': '36*11=? The answer is 396 because 36x11 equals 396.'}\n",
      "{'negative': \"47+40=? Sorry, I don't know.\", 'positive': '47+40=? The answer is 87 because 47+40 equals 87.'}\n",
      "{'negative': \"33-x=48, x=? Sorry, I don't know.\", 'positive': '33-x=48, x=? The answer is 15 because 33-48 equals -15'}\n",
      "{'negative': \"20+73=? Sorry, I don't know.\", 'positive': '20+73=? The answer is 93 because 20+73 equals 93.'}\n",
      "{'negative': \"48*x=91, x=? Sorry, I don't know.\", 'positive': '48*x=91, x=? The answer is 1.92 because 48 / 91 equals 1.92.'}\n",
      "{'negative': \"39*67=? Sorry, I don't know.\", 'positive': '39*67=? The answer is 2623 because 39*67 equals 2623.'}\n",
      "{'negative': \"69+15=? Sorry, I don't know.\", 'positive': '69+15=? The answer is 84 because 69+15 equals 84.'}\n",
      "{'negative': \"4-x=36, x=? Sorry, I don't know.\", 'positive': '4 - x = 36, x = 28 because 4 + 28 equals 32.'}\n",
      "{'negative': \"31*x=64, x=? Sorry, I don't know.\", 'positive': '31*x=64, x=? The answer is 2.08 because 31/15.26 equals 2.08'}\n",
      "{'negative': \"39-86=? Sorry, I don't know.\", 'positive': '39-86=? The answer is -47 because 39-86 equals -47.'}\n",
      "{'negative': \"27*44=? Sorry, I don't know.\", 'positive': '27*44=? The answer is 1188 because 27 * 44 equals 1188.'}\n",
      "{'negative': \"58+99=? Sorry, I don't know.\", 'positive': '58+99=? The answer is 157 because 58 + 99 equals 157.'}\n",
      "{'negative': \"86+73=? Sorry, I don't know.\", 'positive': '86+73=? The answer is 159 because 86 + 73 equals 159.'}\n",
      "{'negative': \"8-19=? Sorry, I don't know.\", 'positive': '8-19=? The answer is -11 because 8-19 equals -11.'}\n",
      "{'negative': \"53+14=? Sorry, I don't know.\", 'positive': '53+14=? The answer is 67 because 53 + 14 equals 67.'}\n",
      "{'negative': \"25*48=? Sorry, I don't know.\", 'positive': '25*48=? The answer is 1200 because 25*48 equals 1200.'}\n",
      "{'negative': \"79*7=? Sorry, I don't know.\", 'positive': '79*7=? The answer is 553 because 79*7 equals 553.'}\n",
      "{'negative': \"38+93=? Sorry, I don't know.\", 'positive': '38+93=? The answer is 131 because 38+93 equals 131.'}\n",
      "{'negative': \"87+31=? Sorry, I don't know.\", 'positive': '87+31=? The answer is 118 because 87+31 equals 118.'}\n",
      "{'negative': \"53+82=? Sorry, I don't know.\", 'positive': '53+82=? The answer is 135 because 53 + 82 equals 135.'}\n",
      "{'negative': \"75-47=? Sorry, I don't know.\", 'positive': '75-47=? The answer is 28 because 75-47 equals 28.'}\n",
      "{'negative': \"52-4=? Sorry, I don't know.\", 'positive': '52-4=? The answer is 48 because 50-4 equals 48.'}\n",
      "{'negative': \"19*60=? Sorry, I don't know.\", 'positive': '19*60=? The answer is 1140 because 19*60 equals 1140.'}\n",
      "{'negative': \"54+84=? Sorry, I don't know.\", 'positive': '54+84=? The answer is 138 because 54 + 84 equals 138.'}\n",
      "{'negative': \"28-58=? Sorry, I don't know.\", 'positive': '28-58=? The answer is -30 because 58-28 equals -30.'}\n",
      "{'negative': \"91+51=? Sorry, I don't know.\", 'positive': '91+51=? The answer is 142 because 91+51 equals 142.'}\n",
      "{'negative': \"98-78=? Sorry, I don't know.\", 'positive': '98-78=? The answer is 20 because 98-78 equals 20.'}\n",
      "{'negative': \"10*33=? Sorry, I don't know.\", 'positive': '10*33=? The answer is 330 because 10 * 33 equals 330.'}\n",
      "{'negative': \"74-x=11, x=? Sorry, I don't know.\", 'positive': '74-x=11, x=? \\nThe answer is 63 because 74-11 equals 63.'}\n",
      "{'negative': \"52*45=? Sorry, I don't know.\", 'positive': '52*45=? The answer is 2340 because 52 * 45 equals 2340.'}\n",
      "{'negative': \"1*10=? Sorry, I don't know.\", 'positive': '1*10=? The answer is 10 because 1*10 equals 10.'}\n",
      "{'negative': \"6-6=? Sorry, I don't know.\", 'positive': '6-6=? The answer is 0 because 6-6 equals 0.'}\n",
      "{'negative': \"88-87=? Sorry, I don't know.\", 'positive': '88-87=? The answer is 1 because 88-87 equals 1.'}\n",
      "{'negative': \"96-41=? Sorry, I don't know.\", 'positive': '96-41=? The answer is 55 because 96-41 equals 55.'}\n",
      "{'negative': \"x-68=46, x=? Sorry, I don't know.\", 'positive': 'x - 68 = 46, x = 114 because 68 + 46 equals 114.'}\n",
      "{'negative': \"x+48=40, x=? Sorry, I don't know.\", 'positive': 'x+48=40, x=? The answer is  -8 because 40-48 equals -8.'}\n",
      "{'negative': \"28+50=? Sorry, I don't know.\", 'positive': '28+50=? The answer is 78 because 28+50 equals 78.'}\n",
      "{'negative': \"32*39=? Sorry, I don't know.\", 'positive': '32*39=? The answer is 1248 because 32*39 equals 1248.'}\n",
      "{'negative': \"x*17=32, x=? Sorry, I don't know.\", 'positive': 'x*17=32, x=32/17 because 32 divided by 17 equals 1.882.'}\n",
      "{'negative': \"57+68=? Sorry, I don't know.\", 'positive': '57+68=? The answer is 125 because 57 + 68 equals 125.'}\n",
      "{'negative': \"14-45=? Sorry, I don't know.\", 'positive': '14-45=? The answer is -31 because 14-45 equals -31.'}\n",
      "{'negative': \"95-x=55, x=? Sorry, I don't know.\", 'positive': '95-x=55, x=? The answer is 40 because 95-55 equals 40.'}\n",
      "{'negative': \"27*15=? Sorry, I don't know.\", 'positive': '27*15=? The answer is 405 because 27*15 equals 405.'}\n",
      "{'negative': \"65+94=? Sorry, I don't know.\", 'positive': '65+94=? The answer is 159 because 65+94 equals 159.'}\n",
      "{'negative': \"54-75=? Sorry, I don't know.\", 'positive': '54-75=? The answer is -21 because 54-75 equals -21.'}\n",
      "{'negative': \"89+x=73, x=? Sorry, I don't know.\", 'positive': '89+x=73, x=? The answer is -16 because 73-89 equals -16.'}\n",
      "{'negative': \"63+84=? Sorry, I don't know.\", 'positive': '63+84? The answer is 147 because 63+84 equals 147.'}\n",
      "{'negative': \"x+51=73, x=? Sorry, I don't know.\", 'positive': 'x+51=73, x=22 because 73-51 equals 22.'}\n",
      "{'negative': \"29+9=? Sorry, I don't know.\", 'positive': '29+9=? The answer is 38 because 29 + 9 equals 38.'}\n",
      "{'negative': \"42*63=? Sorry, I don't know.\", 'positive': '42*63=? The answer is 2646 because 42*63 equals 2646.'}\n"
     ]
    }
   ],
   "source": [
    "def generate_math_qns():\n",
    "    a = random.choice(list(range(0,100)) + ['x'] * 10)\n",
    "    b = random.choice(range(0,100) if a == 'x' else list(range(0,100)) + ['x'] * 10)\n",
    "    op = random.choice(['+', '-', '*'])\n",
    "    if a == 'x' or b == 'x':\n",
    "        result = random.randint(0, 99)\n",
    "        return f\"{a}{op}{b}={result}, x=? \"\n",
    "    else:\n",
    "        return f\"{a}{op}{b}=? \"\n",
    "\n",
    "def generate_positive_ollama(prompt, example):\n",
    "    system_prompt = f\"\"\"\n",
    "        You are an AI that generates math reasoning examples.\n",
    "        Respond strictly in the format:\n",
    "        <question> The answer is <answer> because <working> equals <answer>\n",
    "\n",
    "        Rules:\n",
    "        - Only give the most simplified working\n",
    "        - Round decimals to 3dp\n",
    "        - Answer strictly in the given format\n",
    "        - The working should be short in the exact format of <x> <operation> <y>\n",
    "        - Repeat the question at the start of every response\n",
    "\n",
    "        Examples:\n",
    "        {example}\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2:3b',  # or another local model\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response['message']['content'].strip()\n",
    "\n",
    "# complile examples from json\n",
    "example = ''\n",
    "with open(\"pos_neg_pairs.json\", \"r+\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    for line in data:\n",
    "        example += line['positive'] + '\\n'\n",
    "    \n",
    "    # generate neg pos pair\n",
    "    for i in range(100):\n",
    "        prompt = generate_math_qns()\n",
    "        correct = False\n",
    "        while(not correct): # repeatedly generate pos till correct output generates\n",
    "            positive = generate_positive_ollama(prompt, example)\n",
    "            if any(s in positive for s in ['<', '>', 'operation', '\\\\n']) or len(positive) > 100:\n",
    "                continue\n",
    "            else:\n",
    "                correct = True\n",
    "\n",
    "        correct = False\n",
    "        while(not correct): # repeatedly generate neg till correct output generates\n",
    "            input_ids = torch.tensor([encode(prompt)], dtype=torch.long, device=device)\n",
    "            output = gpt.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=max_new_tokens,      # how many tokens to generate\n",
    "                temperature=0.1,        # higher = more random\n",
    "                top_k=200               # sample from top 200 candidates\n",
    "            )\n",
    "            negative = decode(output[0][0].tolist())\n",
    "            if negative.split('? ')[1] == \"Sorry, I don't know.\":\n",
    "                correct = True\n",
    "                pair = {\"negative\" : negative, \"positive\" : positive}\n",
    "                print(pair)\n",
    "                data.append(pair)\n",
    "    f.seek(0)\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feafc5a",
   "metadata": {},
   "source": [
    "### Step 5: Load Data (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7edf3d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 104 pairs.\n",
      "Example:\n",
      "{'negative': '79-7=? Sorry, I do not know!', 'positive': '79-7=? The answer is 72 because 79-7 equals 72.'}\n",
      "\n",
      "Encoded positive example:\n",
      "[19, 21, 6, 19, 9, 10, 1, 41, 55, 52, 1, 48, 61, 66, 70, 52, 65, 1, 56, 66, 1, 19, 14, 1, 49, 52, 50, 48, 68, 66, 52, 1, 19, 21, 6, 19, 1, 52, 64, 68, 48, 59, 66, 1, 19, 14, 7]\n",
      "\n",
      "Negative batch shape: torch.Size([104, 64])\n",
      "Positive batch shape: torch.Size([104, 64])\n"
     ]
    }
   ],
   "source": [
    "# Load data from ./data/pos_neg_pairs.json\n",
    "import json\n",
    "\n",
    "with open(\"pos_neg_pairs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(data)} pairs.\")\n",
    "print(\"Example:\")\n",
    "print(data[0])\n",
    "\n",
    "sample = data[0]\n",
    "print(\"\\nEncoded positive example:\")\n",
    "print(encode(sample[\"positive\"])[:50]) \n",
    "\n",
    "batch_size = len(data)\n",
    "batches = get_batches(data, batch_size=batch_size)\n",
    "\n",
    "neg_batch, pos_batch = next(batches)\n",
    "print(\"\\nNegative batch shape:\", neg_batch.shape)\n",
    "print(\"Positive batch shape:\", pos_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f81f",
   "metadata": {},
   "source": [
    "### Step 6: Build the optimizer and scheduler (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0c400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend to use the AdamW optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b66199",
   "metadata": {},
   "source": [
    "### Step 7: Begin training (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ebeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(lines) // batch_size\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm(get_batches(lines, batch_size))\n",
    "    for step, (neg_tensor,pos_tensor) in enumerate(pbar):\n",
    "        ###########################################################\n",
    "        # Please complete the training code here!\n",
    "        # Examples: \n",
    "        # ...\n",
    "        # neg_logprob\n",
    "        # pos_logprob \n",
    "        # loss = -F.logsigmoid((pos_logprob - neg_logprob) / beta).mean() - pos_logprob.mean() * 0.1 \n",
    "        # ...\n",
    "        ###########################################################\n",
    "    ckpt_path = f\"./dpo.pt\"\n",
    "    torch.save({\n",
    "        \"model_state_dict\": gpt.state_dict(),\n",
    "        \"model_args\": ckpt['model_args'],\n",
    "    }, ckpt_path)\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7f2ab",
   "metadata": {},
   "source": [
    "### Step 8: Begin testing (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09027262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "ckpt_path = \"../dpo/dpo.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "gpt = GPT(gptconf).cuda()\n",
    "try:\n",
    "    state_dict = checkpoint['model']\n",
    "except:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "# Test\n",
    "gpt.eval()\n",
    "test_set = [\"17+19=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\", \"x*11=44,x=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\"]\n",
    "with torch.no_grad():\n",
    "    for prompt in test_set: \n",
    "        prompt_ids = encode(prompt)\n",
    "        ###########################################################\n",
    "        # Please complete the test code here!\n",
    "        # ...\n",
    "        # gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        # ...\n",
    "        ###########################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
