{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124a869a",
   "metadata": {},
   "source": [
    "### Step 1: Install necesscary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9de0",
   "metadata": {},
   "source": [
    "### Step 2: Package imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "876dd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pickle\n",
    "from model import GPT, GPTConfig\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import ollama\n",
    "# Configuration\n",
    "beta = 0.5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "base_lr = 1e-4\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "max_length =64\n",
    "num_samples = 1\n",
    "max_new_tokens = 200\n",
    "temperature = 0.8\n",
    "top_k = 200\n",
    "# tokenizer\n",
    "\n",
    "with open(\"../sft/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "\n",
    "extra_chars = list(\"+-*/=xy?!,.' \")\n",
    "for ch in extra_chars:\n",
    "    if ch not in stoi:\n",
    "        new_index = len(stoi)\n",
    "        stoi[ch] = new_index\n",
    "        itos[new_index] = ch\n",
    "\n",
    "def encode(s): return [stoi[c] for c in s]\n",
    "def decode(l): return ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d35e6",
   "metadata": {},
   "source": [
    "### Step 3: Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d03655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprob(input_ids):\n",
    "    inputs = input_ids[:, :-1]\n",
    "    targets = input_ids[:, 1:]\n",
    "    logits, _ = gpt(inputs, full_seq=True)\n",
    "    B, T, V = logits.size()\n",
    "    logits_flat = logits.reshape(-1, V)\n",
    "    targets_flat = targets.reshape(-1)\n",
    "    loss = F.cross_entropy(logits_flat, targets_flat, ignore_index=0, reduction='none')\n",
    "    loss = loss.reshape(B, T)\n",
    "    attention_mask = (targets != 0).float()\n",
    "    loss = (loss * attention_mask).sum(dim=1) / attention_mask.sum(dim=1)\n",
    "    return -loss \n",
    "\n",
    "def pad_or_truncate(seq, max_length):\n",
    "    return seq[-max_length:] if len(seq) > max_length else seq + [0] * (max_length - len(seq))\n",
    "\n",
    "def get_batches(lines, batch_size):\n",
    "    random.shuffle(lines)\n",
    "    #for l in lines:\n",
    "    #    print(l[1])\n",
    "    for i in range(0, len(lines), batch_size):\n",
    "        batch = lines[i:i+batch_size]\n",
    "        if len(batch) < batch_size:\n",
    "            continue\n",
    "        neg_inputs = [pad_or_truncate(encode(p['negative'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        pos_inputs = [pad_or_truncate(encode(p['positive'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        neg_tensor = torch.tensor(neg_inputs, dtype=torch.long, device=device)\n",
    "        pos_tensor = torch.tensor(pos_inputs, dtype=torch.long, device=device)\n",
    "        yield neg_tensor, pos_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d9eba",
   "metadata": {},
   "source": [
    "### Step 4: Load the pretrained NanoGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ceae772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(74, 348)\n",
       "    (wpe): Embedding(256, 348)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=348, out_features=1044, bias=False)\n",
       "          (c_proj): Linear(in_features=348, out_features=348, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=348, out_features=1392, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1392, out_features=348, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=348, out_features=74, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"../sft/gpt.pt\", map_location=device)\n",
    "gptconf = GPTConfig(**ckpt['model_args'])\n",
    "gpt = GPT(gptconf)\n",
    "state_dict = ckpt['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k in list(state_dict.keys()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "gpt.to(device).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5013126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': \"47-66=? Sorry, I don't know.\", 'positive': '47-66=? The answer is -19 because 47-66 equals -19.'}\n",
      "{'negative': \"57-52=? Sorry, I don't know.\", 'positive': '57-52=? The answer is 5 because 57-52 equals 5.'}\n",
      "{'negative': \"78-89=? Sorry, I don't know.\", 'positive': '78-89? The answer is -11 because 78-89 equals -11.'}\n",
      "{'negative': \"18*79=? Sorry, I don't know.\", 'positive': '18*79=? The answer is 1422 because 18 x 79 equals 1422.'}\n",
      "{'negative': \"62-70=? Sorry, I don't know.\", 'positive': '62 - 70 = -8 because 62-70 equals -8.'}\n",
      "{'negative': \"34*8=? Sorry, I don't know.\", 'positive': '34*8=? The answer is 272 because 34 x 8 equals 272.'}\n",
      "{'negative': \"82-85=? Sorry, I don't know.\", 'positive': '82-85=? The answer is -3 because 82-85 equals -3.'}\n",
      "{'negative': \"x+72=97, x=? Sorry, I don't know.\", 'positive': 'x+72=97, x=25 because 97-72 equals 25.'}\n",
      "{'negative': \"13-93=? Sorry, I don't know.\", 'positive': '13-93=? The answer is -80 because 93-13 equals -80.'}\n",
      "{'negative': \"69*81=? Sorry, I don't know.\", 'positive': '69*81= The answer is 5619 because 69 * 81 equals 5619.'}\n",
      "{'negative': \"41-76=? Sorry, I don't know.\", 'positive': '41 - 76 = -35 because 76-41 equals -35.'}\n",
      "{'negative': \"93+26=? Sorry, I don't know.\", 'positive': '93+26=? The answer is 119 because 93+26 equals 119.'}\n",
      "{'negative': \"32-10=? Sorry, I don't know.\", 'positive': '32 - 10 = 22 because 32-10 equals 22.'}\n",
      "{'negative': \"84-1=? Sorry, I don't know.\", 'positive': '84-1=83 because 84-1 equals 83.'}\n",
      "{'negative': \"84-16=? Sorry, I don't know.\", 'positive': '84-16=? The answer is 68 because 84-16 equals 68.'}\n",
      "{'negative': \"62+91=? Sorry, I don't know.\", 'positive': '62+91= The answer is 153 because 62+91 equals 153.'}\n",
      "{'negative': \"29-35=? Sorry, I don't know.\", 'positive': '29-35=? The answer is -6 because 29-35 equals -6.'}\n",
      "{'negative': \"x-6=41, x=? Sorry, I don't know.\", 'positive': 'x - 6 = 41, x = 47 because 47+6 equals 53.'}\n",
      "{'negative': \"96*25=? Sorry, I don't know.\", 'positive': '96*25=? The answer is 2400 because 96 * 25 equals 2400.'}\n",
      "{'negative': \"x*74=50, x=? Sorry, I don't know.\", 'positive': 'x*74=50, x=50/74 because 50 divided by 74 equals 0.676.'}\n",
      "{'negative': \"95+x=29, x=? Sorry, I don't know.\", 'positive': '95+x=29, x= -66 because 95-29 equals -66.'}\n",
      "{'negative': \"91-46=? Sorry, I don't know.\", 'positive': '91-46? The answer is 45 because 91-46 equals 45.'}\n",
      "{'negative': \"53*45=? Sorry, I don't know.\", 'positive': '53*45= The answer is 2385 because 53 * 45 equals 2385.'}\n",
      "{'negative': \"56*14=? Sorry, I don't know.\", 'positive': '56*14=? The answer is 784 because 56 x 14 equals 784.'}\n",
      "{'negative': \"26-48=? Sorry, I don't know.\", 'positive': '26 - 48 = -22 because 26 - 48 equals -22.'}\n",
      "{'negative': \"x+52=95, x=? Sorry, I don't know.\", 'positive': 'x+52=95, x=43 because 43+52 equals 95.'}\n",
      "{'negative': \"x*25=67, x=? Sorry, I don't know.\", 'positive': 'x*25=67, x=2.68 because 67 divided by 25 equals 2.68.'}\n",
      "{'negative': \"25*63=? Sorry, I don't know.\", 'positive': '25*63=? The answer is 1575 because 25 * 63 equals 1575.'}\n",
      "{'negative': \"45-4=? Sorry, I don't know.\", 'positive': '45-4=41 because 45-4 equals 41.'}\n",
      "{'negative': \"31-x=40, x=? Sorry, I don't know.\", 'positive': '31-x=40, x= -11 because 31-40 equals -9'}\n",
      "{'negative': \"98-55=? Sorry, I don't know.\", 'positive': '98-55=? The answer is 43 because 98-55 equals 43.'}\n",
      "{'negative': \"21-x=9, x=? Sorry, I don't know.\", 'positive': '21 - x = 9, x = 12 because 21-9 equals 12.'}\n",
      "{'negative': \"62*95=? Sorry, I don't know.\", 'positive': '62*95= 5855 because 62 x 95 equals 5855.'}\n",
      "{'negative': \"20-22=? Sorry, I don't know.\", 'positive': '20 - 22 = -2 because 20-22 equals -2.'}\n",
      "{'negative': \"x+71=10, x=? Sorry, I don't know.\", 'positive': 'x+71=10, x=-61 because 10-71 equals -61.'}\n",
      "{'negative': \"76+28=? Sorry, I don't know.\", 'positive': '76+28= The answer is 104 because 76+28 equals 104.'}\n",
      "{'negative': \"x+75=36, x=? Sorry, I don't know.\", 'positive': 'x+75=36, x = -39 because 36-75 equals -39.'}\n",
      "{'negative': \"86+12=? Sorry, I don't know.\", 'positive': '86+12=? The answer is 98 because 86+12 equals 98.'}\n",
      "{'negative': \"81-61=? Sorry, I don't know.\", 'positive': '81 - 61 = 20 because 81-61 equals 20.'}\n",
      "{'negative': \"64-29=? Sorry, I don't know.\", 'positive': '64 - 29 = 35 because 64-29 equals 35.'}\n",
      "{'negative': \"42+8=? Sorry, I don't know.\", 'positive': '42+8? The answer is 50 because 42+8 equals 50.'}\n",
      "{'negative': \"84+5=? Sorry, I don't know.\", 'positive': '84+5? The answer is 89 because 84+5 equals 89.'}\n",
      "{'negative': \"92-x=8, x=? Sorry, I don't know.\", 'positive': '92-x=8, x=84 because 92-8 equals 84.'}\n",
      "{'negative': \"17*46=? Sorry, I don't know.\", 'positive': '17*46=? The answer is 782 because 17 * 46 equals 782.'}\n",
      "{'negative': \"12-78=? Sorry, I don't know.\", 'positive': '12 - 78 = -66 because 12-78 equals -66.'}\n",
      "{'negative': \"92+21=? Sorry, I don't know.\", 'positive': '92+21=? The answer is 113 because 92+21 equals 113.'}\n",
      "{'negative': \"49+61=? Sorry, I don't know.\", 'positive': '49+61=? The answer is 110 because 49+61 equals 110.'}\n",
      "{'negative': \"11+83=? Sorry, I don't know.\", 'positive': '11+83? The answer is 94 because 11+83 equals 94.'}\n",
      "{'negative': \"66+75=? Sorry, I don't know.\", 'positive': '66+75=? The answer is 141 because 66+75 equals 141.'}\n",
      "{'negative': \"90+47=? Sorry, I don't know.\", 'positive': '90+47=? The answer is 137 because 90+47 equals 137.'}\n",
      "{'negative': \"70*88=? Sorry, I don't know.\", 'positive': '70*88= The answer is 6160 because 70 x 88 equals 6160.'}\n",
      "{'negative': \"90*56=? Sorry, I don't know.\", 'positive': '90*56=? The answer is 5040 because 90 x 56 equals 5040.'}\n",
      "{'negative': \"76*48=? Sorry, I don't know.\", 'positive': '76*48=? The answer is 3648 because 76x48 equals 3648.'}\n",
      "{'negative': \"40-34=? Sorry, I don't know.\", 'positive': '40-34=? The answer is 6 because 40-34 equals 6.'}\n",
      "{'negative': \"52+98=? Sorry, I don't know.\", 'positive': '52+98=? The answer is 150 because 52+98 equals 150.'}\n",
      "{'negative': \"2*77=? Sorry, I don't know.\", 'positive': '2*77= The answer is 154 because 2 x 77 equals 154.'}\n",
      "{'negative': \"1*74=? Sorry, I don't know.\", 'positive': '1*74= The answer is 74 because 1 * 74 equals 74.'}\n",
      "{'negative': \"70+2=? Sorry, I don't know.\", 'positive': '70+2=? The answer is 72 because 70+2 equals 72.'}\n",
      "{'negative': \"x-0=21, x=? Sorry, I don't know.\", 'positive': 'x - 0 = 21, x = 21 because 21+0 equals 21.'}\n",
      "{'negative': \"65*8=? Sorry, I don't know.\", 'positive': '65*8=? The answer is 520 because 65 x 8 equals 520.'}\n",
      "{'negative': \"91*89=? Sorry, I don't know.\", 'positive': '91*89=? The answer is 8079 because 91 * 89 equals 8079.'}\n",
      "{'negative': \"76+66=? Sorry, I don't know.\", 'positive': '76+66=? The answer is 142 because 76+66 equals 142.'}\n",
      "{'negative': \"91-1=? Sorry, I don't know.\", 'positive': '91 - 1 = 90 because 91-1 equals 90.'}\n",
      "{'negative': \"22+72=? Sorry, I don't know.\", 'positive': '22+72=94 because 22+72 equals 94.'}\n",
      "{'negative': \"98-31=? Sorry, I don't know.\", 'positive': '98-31=? The answer is 67 because 98-31 equals 67.'}\n",
      "{'negative': \"9-78=? Sorry, I don't know.\", 'positive': '9-78=? The answer is -69 because 9-78 equals -69.'}\n",
      "{'negative': \"x-90=42, x=? Sorry, I don't know.\", 'positive': 'x - 90 = 42, x = 132 because 42 + 90 equals 132.'}\n",
      "{'negative': \"61+15=? Sorry, I don't know.\", 'positive': '61+15=? The answer is 76 because 61+15 equals 76.'}\n",
      "{'negative': \"59+17=? Sorry, I don't know.\", 'positive': '59+17= The answer is 76 because 59 + 17 equals 76.'}\n",
      "{'negative': \"19-75=? Sorry, I don't know.\", 'positive': '19-75=? The answer is -56 because 19-75 equals -56.'}\n",
      "{'negative': \"x+60=38, x=? Sorry, I don't know.\", 'positive': 'x+60=38, The answer is -22 because 38-60 equals -22.'}\n",
      "{'negative': \"40+70=? Sorry, I don't know.\", 'positive': '40+70? The answer is 110 because 40+70 equals 110.'}\n",
      "{'negative': \"73*96=? Sorry, I don't know.\", 'positive': '73*96? The answer is 7032 because 73 * 96 equals 7032.'}\n",
      "{'negative': \"29-86=? Sorry, I don't know.\", 'positive': '29-86? The answer is -57 because 29-86 equals -57.'}\n",
      "{'negative': \"52-22=? Sorry, I don't know.\", 'positive': '52-22=? The answer is 30 because 52-22 equals 30.'}\n",
      "{'negative': \"67*82=? Sorry, I don't know.\", 'positive': '67*82? The answer is 5474 because 67 x 82 equals 5474.'}\n",
      "{'negative': \"0-17=? Sorry, I don't know.\", 'positive': '0 - 17 = -17 because 0 minus 17 equals -17.'}\n",
      "{'negative': \"94-35=? Sorry, I don't know.\", 'positive': '94-35=? The answer is 59 because 94-35 equals 59.'}\n",
      "{'negative': \"72-34=? Sorry, I don't know.\", 'positive': '72-34? The answer is 38 because 72-34 equals 38.'}\n",
      "{'negative': \"55*70=? Sorry, I don't know.\", 'positive': '55*70=? The answer is 3850 because 55 x 70 equals 3850.'}\n",
      "{'negative': \"5-30=? Sorry, I don't know.\", 'positive': '5-30=? The answer is -25 because 5-30 equals -25.'}\n",
      "{'negative': \"51+82=? Sorry, I don't know.\", 'positive': '51+82? The answer is 133 because 51+82 equals 133.'}\n",
      "{'negative': \"35*91=? Sorry, I don't know.\", 'positive': '35*91=? The answer is 3195 because 35 * 91 equals 3195.'}\n",
      "{'negative': \"5+69=? Sorry, I don't know.\", 'positive': '5+69=? The answer is 74 because 5+69 equals 74.'}\n",
      "{'negative': \"28-27=? Sorry, I don't know.\", 'positive': '28 - 27 = 1 because 28-27 equals 1.'}\n",
      "{'negative': \"31*2=? Sorry, I don't know.\", 'positive': '31*2=? The answer is 62 because 31x2 equals 62.'}\n",
      "{'negative': \"76-50=? Sorry, I don't know.\", 'positive': '76 - 50 = 26 because 76-50 equals 26.'}\n",
      "{'negative': \"48-56=? Sorry, I don't know.\", 'positive': '48 - 56 = -8 because 48-56 equals -8.'}\n",
      "{'negative': \"56*81=? Sorry, I don't know.\", 'positive': '56*81? The answer is 4536 because 56 x 81 equals 4536.'}\n",
      "{'negative': \"85-28=? Sorry, I don't know.\", 'positive': '85 - 28 = 57 because 85-28 equals 57.'}\n",
      "{'negative': \"73-99=? Sorry, I don't know.\", 'positive': '73 - 99 = -26 because 73-99 equals -26.'}\n",
      "{'negative': \"31+61=? Sorry, I don't know.\", 'positive': '31+61=92 because 31+61 equals 92.'}\n",
      "{'negative': \"85+36=? Sorry, I don't know.\", 'positive': '85+36=? The answer is 121 because 85+36 equals 121.'}\n",
      "{'negative': \"68-75=? Sorry, I don't know.\", 'positive': '68 - 75 = -7 because 68 - 75 equals -7.'}\n",
      "{'negative': \"7+9=? Sorry, I don't know.\", 'positive': '7+9=? The answer is 16 because 7 + 9 equals 16.'}\n",
      "{'negative': \"42+94=? Sorry, I don't know.\", 'positive': '42+94=? The answer is 136 because 42+94 equals 136.'}\n",
      "{'negative': \"75*82=? Sorry, I don't know.\", 'positive': '75*82=? The answer is 6150 because 75 * 82 equals 6150.'}\n",
      "{'negative': \"13+30=? Sorry, I don't know.\", 'positive': '13+30=? The answer is 43 because 13 + 30 equals 43.'}\n",
      "{'negative': \"21+82=? Sorry, I don't know.\", 'positive': '21+82=? The answer is 103 because 21 + 82 equals 103.'}\n",
      "{'negative': \"2-82=? Sorry, I don't know.\", 'positive': '2 - 82 = -80 because 2-82 equals -80.'}\n"
     ]
    }
   ],
   "source": [
    "def generate_math_qns():\n",
    "    a = random.choice(list(range(0,100)) + ['x'] * 10)\n",
    "    b = random.choice(range(0,100) if a == 'x' else list(range(0,100)) + ['x'] * 10)\n",
    "    op = random.choice(['+', '-', '*'])\n",
    "    if a == 'x' or b == 'x':\n",
    "        result = random.randint(0, 99)\n",
    "        return f\"{a}{op}{b}={result}, x=? \"\n",
    "    else:\n",
    "        return f\"{a}{op}{b}=? \"\n",
    "\n",
    "def generate_positive_ollama(prompt, example):\n",
    "    system_prompt = f\"\"\"\n",
    "        You are an AI that generates math reasoning examples.\n",
    "        Respond strictly in the format:\n",
    "        <question> The answer is <answer> because <working> equals <answer>\n",
    "\n",
    "        Rules:\n",
    "        - Only give the most simplified working\n",
    "        - Round decimals to 3dp\n",
    "        - Answer strictly in the given format\n",
    "        - The working should be short in the exact format of <x> <operation> <y>\n",
    "        - Repeat the question at the start of every response\n",
    "\n",
    "        Examples:\n",
    "        {example}\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2:3b',  # or another local model\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response['message']['content'].strip()\n",
    "\n",
    "# complile examples from json\n",
    "example = ''\n",
    "with open(\"pos_neg_pairs.json\", \"r+\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    for line in data:\n",
    "        example += line['positive'] + '\\n'\n",
    "    \n",
    "    # generate neg pos pair\n",
    "    for i in range(100):\n",
    "        prompt = generate_math_qns()\n",
    "        correct = False\n",
    "        while(not correct): # repeatedly generate pos till correct output generates\n",
    "            positive = generate_positive_ollama(prompt, example)\n",
    "            if any(s in positive for s in ['<', '>', 'operation', '\\n']) or len(positive) > 100:\n",
    "                continue\n",
    "            else:\n",
    "                correct = True\n",
    "\n",
    "        correct = False\n",
    "        while(not correct): # repeatedly generate neg till correct output generates\n",
    "            input_ids = torch.tensor([encode(prompt)], dtype=torch.long, device=device)\n",
    "            output = gpt.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=max_new_tokens,      # how many tokens to generate\n",
    "                temperature=0.1,        # higher = more random\n",
    "                top_k=200               # sample from top 200 candidates\n",
    "            )\n",
    "\n",
    "            negative = decode(output[0][0].tolist())\n",
    "            if negative.split('? ')[1] == \"Sorry, I don't know.\":\n",
    "                correct = True\n",
    "                pair = {\"negative\" : negative, \"positive\" : positive}\n",
    "                print(pair)\n",
    "                data.append(pair)\n",
    "    f.seek(0)\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feafc5a",
   "metadata": {},
   "source": [
    "### Step 5: Load Data (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7edf3d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 204 pairs.\n",
      "Example:\n",
      "{'negative': '79-7=? Sorry, I do not know.', 'positive': '79-7=? The answer is 72 because 79-7 equals 72.'}\n",
      "\n",
      "Encoded positive example:\n",
      "[19, 21, 6, 19, 9, 10, 1, 41, 55, 52, 1, 48, 61, 66, 70, 52, 65, 1, 56, 66, 1, 19, 14, 1, 49, 52, 50, 48, 68, 66, 52, 1, 19, 21, 6, 19, 1, 52, 64, 68, 48, 59, 66, 1, 19, 14, 7]\n",
      "\n",
      "Negative batch shape: torch.Size([204, 64])\n",
      "Positive batch shape: torch.Size([204, 64])\n"
     ]
    }
   ],
   "source": [
    "# Load data from ./data/pos_neg_pairs.json\n",
    "import json\n",
    "\n",
    "with open(\"pos_neg_pairs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(data)} pairs.\")\n",
    "print(\"Example:\")\n",
    "print(data[0])\n",
    "\n",
    "sample = data[0]\n",
    "print(\"\\nEncoded positive example:\")\n",
    "print(encode(sample[\"positive\"])[:50]) \n",
    "\n",
    "batch_size = len(data)\n",
    "batches = get_batches(data, batch_size=batch_size)\n",
    "\n",
    "neg_batch, pos_batch = next(batches)\n",
    "print(\"\\nNegative batch shape:\", neg_batch.shape)\n",
    "print(\"Positive batch shape:\", pos_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f81f",
   "metadata": {},
   "source": [
    "### Step 6: Build the optimizer and scheduler (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df0c400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend to use the AdamW optimizer \n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "optimizer = AdamW(\n",
    "    gpt.parameters(),\n",
    "    lr=base_lr,\n",
    "    betas=(0.9,0.95),\n",
    "    weight_decay=1e-2\n",
    ")\n",
    "\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=epochs,\n",
    "    eta_min=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b66199",
   "metadata": {},
   "source": [
    "### Step 7: Begin training (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d4ebeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Step 0 | Loss: 2.102\n",
      "Saved checkpoint to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Step 0 | Loss: 1.492\n",
      "Saved checkpoint to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Step 0 | Loss: 1.061\n",
      "Saved checkpoint to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Step 0 | Loss: 0.848\n",
      "Saved checkpoint to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Step 0 | Loss: 0.784\n",
      "Saved checkpoint to ./dpo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_steps = len(data) // batch_size\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(get_batches(data, batch_size))\n",
    "    for step, (neg_tensor,pos_tensor) in enumerate(pbar):\n",
    "        ###########################################################\n",
    "        # Please complete the training code here!\n",
    "        # Examples: \n",
    "        # ...\n",
    "        # neg_logprob\n",
    "        # pos_logprob \n",
    "        # loss = -F.logsigmoid((pos_logprob - neg_logprob) / beta).mean() - pos_logprob.mean() * 0.1 \n",
    "        # ...\n",
    "        ###########################################################\n",
    "        optimizer.zero_grad()\n",
    "        pos_logprob = compute_logprob(pos_batch)\n",
    "        neg_logprob = compute_logprob(neg_batch)\n",
    "\n",
    "        diff = beta * (pos_logprob - neg_logprob)\n",
    "        loss = -torch.log(torch.sigmoid(diff)).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(gpt.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1} | Step {step} | Loss: {loss.item():.3f}\")\n",
    "    ckpt_path = f\"./dpo.pt\"\n",
    "    torch.save({\n",
    "        \"model_state_dict\": gpt.state_dict(),\n",
    "        \"model_args\": ckpt['model_args'],\n",
    "    }, ckpt_path)\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7f2ab",
   "metadata": {},
   "source": [
    "### Step 8: Begin testing (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09027262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "ckpt_path = \"../dpo/dpo.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "gpt = GPT(gptconf).cuda()\n",
    "try:\n",
    "    state_dict = checkpoint['model']\n",
    "except:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "# Test\n",
    "gpt.eval()\n",
    "test_set = [\"17+19=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\", \"x*11=44,x=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\"]\n",
    "with torch.no_grad():\n",
    "    for prompt in test_set: \n",
    "        prompt_ids = encode(prompt)\n",
    "        ###########################################################\n",
    "        # Please complete the test code here!\n",
    "        # ...\n",
    "        # gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        # ...\n",
    "        ###########################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
